{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TV Script Generation\n",
    "This project generates [Simpsons](https://en.wikipedia.org/wiki/The_Simpsons) TV scripts using RNNs, especially LSTMs. It'll use part of the [Simpsons dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data) of scripts from 27 seasons.  The Neural Network will generate a new TV script for a scene at [Moe's Tavern](https://simpsonswiki.com/wiki/Moe's_Tavern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "data_dir = './data/simpsons/moes_tavern_lines.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "# Removes unnecassary part of data\n",
    "text = text[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 11492\n",
      "Number of scenes: 262\n",
      "Average number of sentences in each scene: 15.248091603053435\n",
      "Number of lines: 4257\n",
      "Average number of words in each line: 11.50434578341555\n",
      "\n",
      "The sentences 0 to 7:\n",
      "Moe_Szyslak: (INTO PHONE) Moe's Tavern. Where the elite meet to drink.\n",
      "Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.\n",
      "Moe_Szyslak: (INTO PHONE) Hold on, I'll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?\n",
      "Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I'm gonna catch you, and I'm gonna carve my name on your back with an ice pick.\n",
      "Moe_Szyslak: What's the matter Homer? You're not your normal effervescent self.\n",
      "Homer_Simpson: I got my problems, Moe. Give me another one.\n",
      "Moe_Szyslak: Homer, hey, you should not drink to forget your problems.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "view_sentence_range = (0, 7)\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Creating dictionary to go from the words to an id: `vocab_to_int`\n",
    "- Creating dictionary to go from the id to word: `int_to_vocab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \n",
    "    counts = Counter(text)\n",
    "    vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "    vocab_to_int = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "    int_to_vocab = {i + 1: word for i, word in enumerate(vocab)}\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks make it hard for the neural network to distinguish between the word \"bye\" and \"bye!\".\n",
    "\n",
    "This dictionary will be used to token the symbols like \"!\" into \"||Exclamation_Mark||\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    d = {'.': '||Period||',  ',': '||Comma||',  '\"': '||Quotation_Mark||', \n",
    "         ';': '||Semicolon||',  '!': '||Exclamation_Mark||',  '?': '||Question_mark||',\n",
    "         '(': '||Left_Parentheses||',  ')': '||Right_Parentheses||',  '--': '||Dash||', '\\n': '||Return||'}\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check Point for Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '||period||'),\n",
       " (2, '||return||'),\n",
       " (3, '||comma||'),\n",
       " (4, '||left_parentheses||'),\n",
       " (5, '||right_parentheses||'),\n",
       " (6, 'the'),\n",
       " (7, 'i'),\n",
       " (8, 'you'),\n",
       " (9, '||exclamation_mark||')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(int_to_vocab.items())[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Checking the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakobtamazyan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: No GPU found. Please use a GPU to train your neural network.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    \n",
    "    Input = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    Targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    LearningRate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    KeepProb = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return Input, Targets, LearningRate, KeepProb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_init_cell(batch_size, num_layers, rnn_size, keep_prob):\n",
    "    \n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    Cell = tf.contrib.rnn.MultiRNNCell([build_cell(rnn_size, keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    InitialState = tf.identity(Cell.zero_state(batch_size, tf.float32), name='initial_state')\n",
    "    return Cell, InitialState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    return embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \n",
    "    Outputs, FinalState = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
    "    FinalState = tf.identity(FinalState, name='final_state')\n",
    "    \n",
    "    return Outputs, FinalState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size, embed_dim):\n",
    "    \n",
    "    embed = get_embed(input_data, vocab_size, embed_dim)\n",
    "    Outputs, FinalState = build_rnn(cell, embed)\n",
    "    Logits = tf.contrib.layers.fully_connected(Outputs, vocab_size, activation_fn=None)\n",
    "    \n",
    "    return Logits, FinalState\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Batches\n",
    "\n",
    "For exmple, `get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 3, 2)` would return a Numpy array of the following:\n",
    "```\n",
    "[\n",
    "  # First Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 1  2], [ 7  8], [13 14]]\n",
    "    # Batch of targets\n",
    "    [[ 2  3], [ 8  9], [14 15]]\n",
    "  ]\n",
    "\n",
    "  # Second Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 3  4], [ 9 10], [15 16]]\n",
    "    # Batch of targets\n",
    "    [[ 4  5], [10 11], [16 17]]\n",
    "  ]\n",
    "\n",
    "  # Third Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 5  6], [11 12], [17 18]]\n",
    "    # Batch of targets\n",
    "    [[ 6  7], [12 13], [18  1]]\n",
    "  ]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \n",
    "    chars_per_batch = batch_size * seq_length\n",
    "    n_batches = len(int_text)//chars_per_batch\n",
    "    \n",
    "    int_text = np.array(int_text)\n",
    "    arr = int_text[:n_batches * chars_per_batch]\n",
    "    \n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    batches = []\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        yy = arr[:, n+1:n+seq_length+1]\n",
    "        \n",
    "        y = np.zeros(x.shape, dtype=x.dtype)\n",
    "        y[:,:yy.shape[1]] = yy\n",
    "        \n",
    "        batches.append([x, y])\n",
    "    \n",
    "    return np.array(batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 80\n",
    "batch_size = 120\n",
    "rnn_size = 512\n",
    "embed_dim = 300\n",
    "seq_length = 32\n",
    "learning_rate = 0.01\n",
    "num_layers = 1\n",
    "keep_prob = 1.0\n",
    "\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text, targets, lr, keep = get_inputs()\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "    cell, initial_state = get_init_cell(input_data_shape[0], num_layers, rnn_size, keep)\n",
    "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size, embed_dim)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "    # Loss function\n",
    "    cost = seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0  train_loss = 5.708\n",
      "Epoch   1  train_loss = 4.911\n",
      "Epoch   2  train_loss = 4.322\n",
      "Epoch   3  train_loss = 3.822\n",
      "Epoch   4  train_loss = 3.399\n",
      "Epoch   5  train_loss = 3.018\n",
      "Epoch   6  train_loss = 2.680\n",
      "Epoch   7  train_loss = 2.390\n",
      "Epoch   8  train_loss = 2.064\n",
      "Epoch   9  train_loss = 1.808\n",
      "Epoch  10  train_loss = 1.603\n",
      "Epoch  11  train_loss = 1.458\n",
      "Epoch  12  train_loss = 1.316\n",
      "Epoch  13  train_loss = 1.188\n",
      "Epoch  14  train_loss = 0.984\n",
      "Epoch  15  train_loss = 0.846\n",
      "Epoch  16  train_loss = 0.688\n",
      "Epoch  17  train_loss = 0.597\n",
      "Epoch  18  train_loss = 0.494\n",
      "Epoch  19  train_loss = 0.431\n",
      "Epoch  20  train_loss = 0.369\n",
      "Epoch  21  train_loss = 0.311\n",
      "Epoch  22  train_loss = 0.258\n",
      "Epoch  23  train_loss = 0.227\n",
      "Epoch  24  train_loss = 0.192\n",
      "Epoch  25  train_loss = 0.163\n",
      "Epoch  26  train_loss = 0.146\n",
      "Epoch  27  train_loss = 0.130\n",
      "Epoch  28  train_loss = 0.122\n",
      "Epoch  29  train_loss = 0.111\n",
      "Epoch  30  train_loss = 0.105\n",
      "Epoch  31  train_loss = 0.098\n",
      "Epoch  32  train_loss = 0.097\n",
      "Epoch  33  train_loss = 0.093\n",
      "Epoch  34  train_loss = 0.093\n",
      "Epoch  35  train_loss = 0.090\n",
      "Epoch  36  train_loss = 0.090\n",
      "Epoch  37  train_loss = 0.088\n",
      "Epoch  38  train_loss = 0.088\n",
      "Epoch  39  train_loss = 0.086\n",
      "Epoch  40  train_loss = 0.087\n",
      "Epoch  41  train_loss = 0.085\n",
      "Epoch  42  train_loss = 0.086\n",
      "Epoch  43  train_loss = 0.084\n",
      "Epoch  44  train_loss = 0.086\n",
      "Epoch  45  train_loss = 0.084\n",
      "Epoch  46  train_loss = 0.085\n",
      "Epoch  47  train_loss = 0.083\n",
      "Epoch  48  train_loss = 0.084\n",
      "Epoch  49  train_loss = 0.083\n",
      "Epoch  50  train_loss = 0.084\n",
      "Epoch  51  train_loss = 0.082\n",
      "Epoch  52  train_loss = 0.084\n",
      "Epoch  53  train_loss = 0.082\n",
      "Epoch  54  train_loss = 0.083\n",
      "Epoch  55  train_loss = 0.082\n",
      "Epoch  56  train_loss = 0.083\n",
      "Epoch  57  train_loss = 0.082\n",
      "Epoch  58  train_loss = 0.083\n",
      "Epoch  59  train_loss = 0.081\n",
      "Epoch  60  train_loss = 0.083\n",
      "Epoch  61  train_loss = 0.081\n",
      "Epoch  62  train_loss = 0.082\n",
      "Epoch  63  train_loss = 0.081\n",
      "Epoch  64  train_loss = 0.082\n",
      "Epoch  65  train_loss = 0.081\n",
      "Epoch  66  train_loss = 0.082\n",
      "Epoch  67  train_loss = 0.081\n",
      "Epoch  68  train_loss = 0.082\n",
      "Epoch  69  train_loss = 0.081\n",
      "Epoch  70  train_loss = 0.082\n",
      "Epoch  71  train_loss = 0.080\n",
      "Epoch  72  train_loss = 0.082\n",
      "Epoch  73  train_loss = 0.080\n",
      "Epoch  74  train_loss = 0.082\n",
      "Epoch  75  train_loss = 0.080\n",
      "Epoch  76  train_loss = 0.081\n",
      "Epoch  77  train_loss = 0.080\n",
      "Epoch  78  train_loss = 0.081\n",
      "Epoch  79  train_loss = 0.080\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches):\n",
    "            feed = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate,\n",
    "                keep: keep_prob}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "        print('Epoch {:>3}  train_loss = {:.3f}'.format(epoch_i, train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save parameters for checkpoint\n",
    "helper.save_params((seq_length, save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakobtamazyan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    \n",
    "    InputTensor = loaded_graph.get_tensor_by_name('input:0')\n",
    "    KeepProbTensor = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    InitialStateTensor = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    FinalStateTensor = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    ProbsTensor = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    \n",
    "    return InputTensor, KeepProbTensor, InitialStateTensor, FinalStateTensor, ProbsTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pick_word(probabilities, int_to_vocab, top_n=4):\n",
    "    \n",
    "    p = np.squeeze(probabilities)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    word_id = np.random.choice(len(p), p=p)\n",
    "\n",
    "    return int_to_vocab[word_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate TV Script\n",
    "This will generate the TV script for you.  Set `gen_length` to the length of TV script you want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "\n",
      "moe_szyslak:(stunned) nigeria?\n",
      "moe_szyslak:(repressed rage) homer, can i speak to you in private?\n",
      "homer_simpson: can i try it?\n",
      "moe_szyslak: eh, this is serious. this bashir kid is muslim, and therefore up to the pool table.\n",
      "little_hibbert_girl: daddy, this place smells like tinkle.\n",
      "dr. _julius_hibbert: mmm-hmm, i'm going to use your tongue to paint my boat.\n",
      "waylon_smithers: uh, hello, is there anything in?\n",
      "moe_szyslak: uh, let me check the lost and found.\n",
      "moe_szyslak: what do we got to do something to change his war.\n",
      "lenny_leonard: that's right, brainiac. you cost us our jobs, which we need for workin'.\n",
      "homer_simpson: hi, moe.\n",
      "moe_szyslak: okay, homer, i was so self-centered. no wonder i didn't see it coming.(shaking head) that's how it is, though: a minute. i gotta get back to the back of...\n",
      "barney_gumble: you know, i heard the jackpot's up to one hundred and thirty million dollars.\n"
     ]
    }
   ],
   "source": [
    "gen_length = 200\n",
    "# homer_simpson, moe_szyslak, or Barney_Gumble\n",
    "prime_word = 'moe_szyslak'\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    input_text, keep, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word + ':']\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, keep: 1.0, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[:, dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "        \n",
    "    print()\n",
    "    print(tv_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
